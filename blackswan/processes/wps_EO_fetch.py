from pywps import Process
# from pywps import LiteralInput
from pywps import ComplexInput, LiteralInput, ComplexOutput
from pywps import Format, FORMATS
from pywps.app.Common import Metadata

from flyingpigeon.log import init_process_logger
from flyingpigeon.utils import rename_complexinputs

# from flyingpigeon.datafetch import write_fileinfo
from flyingpigeon.datafetch import fetch_eodata
from flyingpigeon.datafetch import _EODATA_

import os
from datetime import datetime as dt
from datetime import timedelta, time
from tempfile import mkstemp

import logging
LOGGER = logging.getLogger("PYWPS")


class FetcheodataProcess(Process):
    """
    TODO: like FetchProcess
    """
    def __init__(self):
        inputs = [
            LiteralInput("products", "Earth Observation Product",
                         abstract="Choose Earth Observation Products (up to five)",
                         default="PSScene3Band__visual",
                         data_type='string',
                         min_occurs=1,
                         max_occurs=5,
                         allowed_values=_EODATA_
                         ),

            LiteralInput('BBox', 'Bounding Box',
                         data_type='string',
                         abstract="Enter a bbox: min_lon, max_lon, min_lat, max_lat."
                                  " min_lon=Western longitude,"
                                  " max_lon=Eastern longitude,"
                                  " min_lat=Southern or northern latitude,"
                                  " max_lat=Northern or southern latitude."
                                  " For example: -80,50,20,70",
                         min_occurs=1,
                         max_occurs=1,
                         default='14,15,8,9',
                         ),

            LiteralInput('start', 'Start Date',
                         data_type='date',
                         abstract='First day of the period to be searched for EO data.'
                                  '(if not set, 30 days befor end of period will be selected',
                         default=(dt.now() - timedelta(days=30)).strftime('%Y-%m-%d'),
                         min_occurs=0,
                         max_occurs=1,
                         ),

            LiteralInput('end', 'End Date',
                         data_type='date',
                         abstract='Last day of the period to be searched for EO data.'
                                  '(if not set, current day is set.)',
                         default=dt.now().strftime('%Y-%m-%d'),
                         min_occurs=0,
                         max_occurs=1,
                         ),

            LiteralInput('token', 'Authentification',
                         data_type='string',
                         abstract='Authentification token generated by Planet Earth Observation Explorer.',
                         # default='2013-12-31',
                         min_occurs=1,
                         max_occurs=1,
                         ),

            #
            # ComplexInput('resource', 'Resource',
            #              abstract="NetCDF Files or archive (tar/zip) containing netCDF files.",
            #              min_occurs=1,
            #              max_occurs=1000,
            #              #  maxmegabites=5000,
            #              supported_formats=[Format('application/x-netcdf'),
            #                                 Format('application/x-tar'),
            #                                 Format('application/zip'),
            #                                 ]
            #              )
        ]

        outputs = [
            ComplexOutput("output", "Fetched Files",
                          abstract="File containing the local pathes to downloades files.",
                          supported_formats=[Format('text/plain')],
                          as_reference=True,
                          ),

            ComplexOutput("output_log", "Logging information",
                          abstract="Collected logs during process run.",
                          supported_formats=[Format("text/plain")],
                          as_reference=True,
                          )
        ]

        super(FetcheodataProcess, self).__init__(
            self._handler,
            identifier="EO_fetch",
            title="Earth Observation Fetch Resources",
            version="0.1",
            abstract="Fetch EO Data to the local file"
                     "system of the birdhouse compute provider.",
            metadata=[
                Metadata('Documentation', 'http://flyingpigeon.readthedocs.io/en/latest/'),
            ],
            inputs=inputs,
            outputs=outputs,
            status_supported=True,
            store_supported=True,
        )

    def _handler(self, request, response):
        response.update_status("start fetching resource", 10)

        init_process_logger('log.txt')
        response.outputs['output_log'].file = 'log.txt'

        products = [inpt.data for inpt in request.inputs['products']]

        bbox = []  # order xmin ymin xmax ymax
        bboxStr = request.inputs['BBox'][0].data
        bboxStr = bboxStr.split(',')
        bbox.append(float(bboxStr[0]))
        bbox.append(float(bboxStr[2]))
        bbox.append(float(bboxStr[1]))
        bbox.append(float(bboxStr[3]))

        if 'end' in request.inputs:
            end = request.inputs['end'][0].data
            end = dt.combine(end, time(23, 59, 59))
        else:
            end = dt.now()

        if 'start' in request.inputs:
            start = request.inputs['start'][0].data
            start = dt.combine(start, time(0, 0, 0))
        else:
            start = end - timedelta(days=30)

        if (start > end):
            start = dt.now() - timedelta(days=30)
            end = dt.now()
            LOGGER.exception("periode end befor periode start, period is set to the last 30 days from now")

        token = request.inputs['token'][0].data

        resources = []
        resources_sleeping = []
        for product in products:
            item_type, asset = product.split('__')
            LOGGER.debug('itym type: %s , asset: %s' % (item_type, asset))
            fetch_sleep, fetch = fetch_eodata(item_type,
                                              asset,
                                              token,
                                              bbox,
                                              period=[start, end],
                                              cloud_cover=0.5,
                                              cache=True)
            resources.extend(fetch)
            resources_sleeping.extend(fetch_sleep)

        _, filepathes = mkstemp(dir='.', suffix='.txt')
        try:
            with open(filepathes, 'w') as fp:
                fp.write('######################################################\n')
                fp.write('### Following files are stored to compute provider ###:\n')
                fp.write('######################################################\n')
                fp.write('\n')
                for f in resources:
                    fp.write('%s \n' % os.path.realpath(f))
                fp.write('/n')
                fp.write('/n')
                fp.write('######################################################\n')
                fp.write('### Following files didn\'t want to wake up       ###:\n')
                fp.write('######################################################\n')
                for f in resources_sleeping:
                    fp.write('%s \n' % f)
            response.outputs['output'].file = filepathes
        except:
            LOGGER.exception('failed to write resources to textfile')
        # response.outputs['output'].file = write_fileinfo(resource, filepath=True)
        response.update_status("done", 100)

        return response
